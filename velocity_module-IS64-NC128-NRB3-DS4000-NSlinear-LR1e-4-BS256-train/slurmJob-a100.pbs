#!/bin/bash
#SBATCH -p std
#SBATCH --time 24:00:00      # format: HH:MM:SS
##SBATCH -w a100-2           # ask for specific host
#SBATCH -N 1                 # xxx node
#SBATCH --ntasks-per-node=16 # xxx core per node
#SBATCH --gres=gpu:a100:4    # xxx gpus per node
#SBATCH --mem=256000         # memory per node out of xxx MB
#SBATCH --job-name=DT-train
##SBATCH --mail-type=ALL
##SBATCH --mail-user=<user_email>

echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"

source ~/.bashrc
conda activate diffusion-turb

export OPENAI_LOGDIR="/mnt/petaStor/li/Job/diffusion-turb/velocity_module-IS64-NC128-NRB3-DS4000-NSlinear-LR1e-4-BS256-train"

DATA_FLAGS="--dataset_path /mnt/petaStor/li/Job/diffusion-turb/datasets/TURB-Rot_new-data_module_diffusion.h5 --dataset_name train"
MODEL_FLAGS="--image_size 64 --in_channels 1 --num_channels 128 --num_res_blocks 3"
DIFFUSION_FLAGS="--diffusion_steps 4000 --noise_schedule linear"
TRAIN_FLAGS="--lr 1e-4 --batch_size 64"

mpiexec -n 4 python ../scripts/turb_train.py $DATA_FLAGS $MODEL_FLAGS $DIFFUSION_FLAGS $TRAIN_FLAGS
